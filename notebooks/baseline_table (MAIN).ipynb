{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline table - Sepsis manuscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates the baseline table for the sepsis manuscript."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets setup the notebook settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Desktop\\Sepsis\\src\n"
     ]
    }
   ],
   "source": [
    "%cd ../src\n",
    "%pwd\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import all important libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "# utils import\n",
    "from utils.files import get_latest_version\n",
    "from utils.cross_validation import cross_validate_ROC, cross_validate_risk_ROC, compare_models\n",
    "from utils.risk_scores import read_data_risk_score\n",
    "\n",
    "# xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read all the data from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 24\n",
    "model_dir = [x for x in os.listdir(os.path.join(os.getcwd(), '..', \n",
    "                                                    'models')) if str(model_version).zfill(3) in x][0]\n",
    "\n",
    "model_main_file = \"model_{}_out_{}_maindb.csv\".format(3, 1)\n",
    "model_val_file = \"model_{}_out_{}_validationdb.csv\".format(3, 1)\n",
    "\n",
    "df = pd.read_csv(os.path.join(os.getcwd(), '..', 'models', model_dir, model_main_file), \n",
    "                      sep =',', \n",
    "                      header=0,\n",
    "                      infer_datetime_format=True, \n",
    "                      error_bad_lines=False, \n",
    "                      engine='python',\n",
    "                      encoding='utf-8')\n",
    "\n",
    "df_valid = pd.read_csv(os.path.join(os.getcwd(), '..', 'models', model_dir, model_val_file), \n",
    "                      sep =',', \n",
    "                      header=0,\n",
    "                      infer_datetime_format=True, \n",
    "                      error_bad_lines=False, \n",
    "                      engine='python',\n",
    "                      encoding='utf-8')\n",
    "\n",
    "df_total = pd.concat([df, df_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we first define the _abbMEDS function according to the paper of\n",
    "Vorwerk et al 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meds clinical risk score\n",
    "def _abbMEDS(row):\n",
    "    points = 0\n",
    "    \n",
    "    #rule 1\n",
    "    if row['metastase_of_chronische_ziekte_met_hoge_mortaliteit'] == 1:\n",
    "        points += 6\n",
    "        \n",
    "    #rule 2\n",
    "    if row['AF_berekend'] > 20:\n",
    "        points += 3\n",
    "    \n",
    "    #rule 3\n",
    "    if row['y_var'] == 1: # hardcode septic shock\n",
    "        points += 3\n",
    "    \n",
    "    #rule 4\n",
    "    if row['TRC'] < 150:\n",
    "        points += 3\n",
    "    \n",
    "    #rule 5\n",
    "    if row['Geboortedatum'] >= 65:\n",
    "        points += 3\n",
    "        \n",
    "    #rule 6        \n",
    "    if row['WD'] == 2:\n",
    "        points += 2\n",
    "    \n",
    "    #rule 7\n",
    "    if row['Woonsituatie'] in [2,3]:\n",
    "        points += 2\n",
    "        \n",
    "    #rule 8   \n",
    "    if row['Comorb_dementie_Psychiatrisch']:\n",
    "        points += 2\n",
    "        \n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the mREMS clinical risk score according to Crowe et al. 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mREMS(row):\n",
    "    points = 0\n",
    "    \n",
    "    #rule 1\n",
    "    points += np.where(row['Geboortedatum'] < 45, 0, \n",
    "                       np.where(row['Geboortedatum'] < 54, 2,\n",
    "                        np.where(row['Geboortedatum'] < 64, 3, \n",
    "                         np.where(row['Geboortedatum'] < 74, 5, 6))))\n",
    "    # rule 2\n",
    "    points += np.where(row['Pols'] < 39, 4,\n",
    "               np.where(row['Pols'] < 55, 3,\n",
    "                 np.where(row['Pols'] < 70, 2,\n",
    "                  np.where(row['Pols'] < 110, 0,\n",
    "                   np.where(row['Pols'] < 139, 2,\n",
    "                    np.where(row['Pols'] < 179, 3, 4))))))\n",
    "    \n",
    "    # rule 3\n",
    "    points += np.where(row['AF_berekend'] < 5, 4,\n",
    "               np.where(row['AF_berekend'] < 9, 3,\n",
    "                 np.where(row['AF_berekend'] < 12, 1,\n",
    "                  np.where(row['AF_berekend'] < 25, 0,\n",
    "                   np.where(row['AF_berekend'] < 35, 1,\n",
    "                    np.where(row['AF_berekend'] < 50, 3, 4))))))\n",
    "    \n",
    "    # rule 4\n",
    "    RR_map = ((row['RR_syst'] + 2 * row['RR_diast'])/3)\n",
    "    points += np.where(RR_map < 49, 4,\n",
    "               np.where(RR_map < 70, 2,\n",
    "                np.where(RR_map < 110, 0,\n",
    "                 np.where(RR_map < 130, 2,\n",
    "                  np.where(RR_map < 160, 3, 4)))))\n",
    "    \n",
    "    # rule 5\n",
    "    points += np.where(row['Saturatie'] == 0, 0,\n",
    "                np.where(row['Saturatie'] < 75, 4,\n",
    "                 np.where(row['Saturatie'] < 85, 3,\n",
    "                  np.where(row['Saturatie'] < 90, 1, 0))))\n",
    "    \n",
    "    #rule 6\n",
    "    points += np.where(row['GCS_afgeleid'] > 13, 1,\n",
    "                np.where(row['GCS_afgeleid'] > 11, 1,\n",
    "                 np.where(row['GCS_afgeleid'] > 8, 2,\n",
    "                  np.where(row['GCS_afgeleid'] > 5, 3, 4))))\n",
    "    \n",
    "    if row['Comorb_dementie_Psychiatrisch']:\n",
    "        points += 1\n",
    "        \n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a small helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _score_to_risk(_df):\n",
    "    df['abbMEDS_risk'] = np.where(df['abbMEDS'] < 5, 0.016, \n",
    "                                  np.where(df['abbMEDS'] < 13, 0.234, 0.59))\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate the scores for each of the dataframes:\n",
    "    - df ; main DB\n",
    "    - df_valid ; validation DB\n",
    "    - df_total ; total DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 9, 6, 10, 4, 6, 10, 3, 7, 1, 9, 7, 1, 6, 11, 11, 6, 7, 9, 3, 7, 8, 3, 7, 1, 6, 6, 8, 12, 11, 7, 13, 7, 7, 5, 9, 8, 5, 12, 1, 9, 10, 7, 4, 7, 7, 10, 11, 9, 4, 6, 5, 9, 10, 7, 7, 4, 8, 7, 10, 12, 3, 8, 6, 6, 7, 1, 9, 9, 9, 6, 8, 6, 8, 4, 5, 7, 10, 7, 7, 11, 7, 6, 7, 6, 1, 7, 10, 10, 7, 11, 1, 3, 7, 10, 8, 7, 7, 3, 11]\n"
     ]
    }
   ],
   "source": [
    "df['abbMEDS'] = df.apply(_abbMEDS, axis=1)\n",
    "df['mREMS'] = df.apply(_mREMS, axis=1)\n",
    "\n",
    "df_valid['abbMEDS'] = df_valid.apply(_abbMEDS, axis=1)\n",
    "df_valid['mREMS'] = df_valid.apply(_mREMS, axis=1)\n",
    "\n",
    "df_total['abbMEDS'] = df_total.apply(_abbMEDS, axis=1)\n",
    "df_total['mREMS'] = df_total.apply(_mREMS, axis=1)\n",
    "\n",
    "print(list(df_valid['mREMS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate median +- IQR for each of the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1244.000000\n",
      "mean        5.761254\n",
      "std         3.958767\n",
      "min         0.000000\n",
      "25%         3.000000\n",
      "50%         6.000000\n",
      "75%         8.000000\n",
      "max        20.000000\n",
      "Name: abbMEDS, dtype: float64\n",
      "count    1244.000000\n",
      "mean        7.357717\n",
      "std         2.967756\n",
      "min         1.000000\n",
      "25%         6.000000\n",
      "50%         7.000000\n",
      "75%         9.000000\n",
      "max        19.000000\n",
      "Name: mREMS, dtype: float64\n",
      "count    100.000000\n",
      "mean       5.750000\n",
      "std        3.748063\n",
      "min        0.000000\n",
      "25%        3.000000\n",
      "50%        5.500000\n",
      "75%        8.000000\n",
      "max       17.000000\n",
      "Name: abbMEDS, dtype: float64\n",
      "count    100.000000\n",
      "mean       7.020000\n",
      "std        2.828356\n",
      "min        1.000000\n",
      "25%        6.000000\n",
      "50%        7.000000\n",
      "75%        9.000000\n",
      "max       13.000000\n",
      "Name: mREMS, dtype: float64\n",
      "count    1344.000000\n",
      "mean        5.760417\n",
      "std         3.942141\n",
      "min         0.000000\n",
      "25%         3.000000\n",
      "50%         6.000000\n",
      "75%         8.000000\n",
      "max        20.000000\n",
      "Name: abbMEDS, dtype: float64\n",
      "count    1344.000000\n",
      "mean        7.332589\n",
      "std         2.957924\n",
      "min         1.000000\n",
      "25%         6.000000\n",
      "50%         7.000000\n",
      "75%         9.000000\n",
      "max        19.000000\n",
      "Name: mREMS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for d in [df, df_valid, df_total]:\n",
    "    print(d['abbMEDS'].describe())\n",
    "    print(d['mREMS'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should use mann-whitney U to check for differences between the two groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MannwhitneyuResult(statistic=62056.0, pvalue=0.4845207181967723)\n",
      "MannwhitneyuResult(statistic=59154.5, pvalue=0.2055895745049367)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "print(mannwhitneyu(df['abbMEDS'], df_valid['abbMEDS']))\n",
    "print(mannwhitneyu(df['mREMS'], df_valid['mREMS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we read all data for output 1 (shock) and output (3) mortality into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 24\n",
    "model_dir = [x for x in os.listdir(os.path.join(os.getcwd(), '..', \n",
    "                                                    'models')) if str(model_version).zfill(3) in x][0]\n",
    "\n",
    "model_main_file = \"model_{}_out_{}_maindb.csv\".format(3, 1)\n",
    "model_val_file = \"model_{}_out_{}_validationdb.csv\".format(3, 1)\n",
    "\n",
    "df_main_shock = pd.read_csv(os.path.join(os.getcwd(), '..', 'models', model_dir, model_main_file), \n",
    "                      sep =',', \n",
    "                      header=0,\n",
    "                      infer_datetime_format=True, \n",
    "                      error_bad_lines=False, \n",
    "                      engine='python',\n",
    "                      encoding='utf-8')\n",
    "\n",
    "df_valid_shock = pd.read_csv(os.path.join(os.getcwd(), '..', 'models', model_dir, model_val_file), \n",
    "                      sep =',', \n",
    "                      header=0,\n",
    "                      infer_datetime_format=True, \n",
    "                      error_bad_lines=False, \n",
    "                      engine='python',\n",
    "                      encoding='utf-8')\n",
    "\n",
    "df_total_shock = pd.concat([df, df_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 22\n",
    "model_dir = [x for x in os.listdir(os.path.join(os.getcwd(), '..', \n",
    "                                                    'models')) if str(model_version).zfill(3) in x][0]\n",
    "\n",
    "model_main_file = \"model_{}_out_{}_maindb.csv\".format(3, 3)\n",
    "model_val_file = \"model_{}_out_{}_validationdb.csv\".format(3, 3)\n",
    "\n",
    "df_main_mort = pd.read_csv(os.path.join(os.getcwd(), '..', 'models', model_dir, model_main_file), \n",
    "                      sep =',', \n",
    "                      header=0,\n",
    "                      infer_datetime_format=True, \n",
    "                      error_bad_lines=False, \n",
    "                      engine='python',\n",
    "                      encoding='utf-8')\n",
    "\n",
    "df_valid_mort = pd.read_csv(os.path.join(os.getcwd(), '..', 'models', model_dir, model_val_file), \n",
    "                      sep =',', \n",
    "                      header=0,\n",
    "                      infer_datetime_format=True, \n",
    "                      error_bad_lines=False, \n",
    "                      engine='python',\n",
    "                      encoding='utf-8')\n",
    "\n",
    "df_total_mort = pd.concat([df_main_mort, df_valid_mort])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the relative frequencies of both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1150\n",
      "1      94\n",
      "Name: y_var, dtype: int64\n",
      "0    92\n",
      "1     8\n",
      "Name: y_var, dtype: int64\n",
      "0    1242\n",
      "1     102\n",
      "Name: y_var, dtype: int64\n",
      "0    1083\n",
      "1     161\n",
      "Name: y_var, dtype: int64\n",
      "0    87\n",
      "1    13\n",
      "Name: y_var, dtype: int64\n",
      "0    1170\n",
      "1     174\n",
      "Name: y_var, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for d in [df_main_shock, df_valid_shock, df_total_shock]:\n",
    "    print(d['y_var'].value_counts())\n",
    "    \n",
    "for d in [df_main_mort, df_valid_mort, df_total_mort]:\n",
    "    print(d['y_var'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our own chi_square function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square(maincol, validcol):\n",
    "    values = list(maincol) + list(validcol)\n",
    "    _df = pd.DataFrame({'values' : values, 'cohort' : [0] * len(maincol) + [1] * len(validcol)})\n",
    "    return chi2_contingency(pd.crosstab(_df['values'], _df['cohort']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate chi-square values for both septic shock as well as mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0012280600762603275,\n",
       " 0.9720449041777297,\n",
       " 1,\n",
       " array([[1149.58928571,   92.41071429],\n",
       "        [  94.41071429,    7.58928571]]))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_square(df_main_shock['y_var'], df_valid_shock['y_var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.019104966438373797,\n",
       " 0.890065982933238,\n",
       " 1,\n",
       " array([[1082.94642857,   87.05357143],\n",
       "        [ 161.05357143,   12.94642857]]))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_square(df_main_mort['y_var'], df_valid_mort['y_var'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
